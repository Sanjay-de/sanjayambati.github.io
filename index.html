<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Sanjay Ambati | Data Engineer</title>

  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="style.css"/>
</head>
<body>

  <!-- HERO -->
  <header class="hero">
    <div class="hero-inner">
      <h1>I build data systems that donâ€™t break at scale.</h1>
      <p class="hero-sub">
        Data Engineer Â· 4 years Â· Databricks Â· AWS Â· Redshift
      </p>

      <div class="hero-actions">
        <a href="#work" class="btn">View My Work</a>
        <a href="Sanjay_ambati_DE.pdf" class="btn outline" download>Download Resume</a>
      </div>

      <div class="tech-strip">
        Databricks Â· Spark Â· S3 Â· Glue Â· Redshift Â· Athena Â· Kinesis Â· Airflow
      </div>
    </div>
  </header>

  <!-- ABOUT -->
  <section class="section">
    <h2>About Me</h2>
    <p>
      I am a Data Engineer with 4 years of experience designing and building
      scalable batch and streaming data platforms. I specialize in cloud-native
      architectures, data reliability, and performance optimization using
      Databricks, PySpark, AWS, and SQL.
    </p>
  </section>

  <!-- HOW I THINK -->
  <section class="section alt">
    <h2>How I Think as a Data Engineer</h2>
    <ul class="list">
      <li>Reliability over speed</li>
      <li>Observability over blind execution</li>
      <li>Cost-awareness over brute force</li>
      <li>Automation over manual intervention</li>
    </ul>
  </section>

  <!-- ARCHITECTURE -->
  <section class="section">
    <h2>Architecture & Data Flow</h2>
    <div class="architecture">
      <span>Sources</span> â†’
      <span>Ingestion</span> â†’
      <span>Processing</span> â†’
      <span>Storage</span> â†’
      <span>Analytics</span> â†’
      <span>Orchestration</span>
    </div>

    <ul class="list">
      <li>Sources: On-prem DBs, APIs, SFTP, streaming systems</li>
      <li>Ingestion: AWS DMS, Lambda, Kinesis, Glue</li>
      <li>Processing: Databricks (PySpark), EMR</li>
      <li>Storage: Amazon S3 (Parquet, partitioned)</li>
      <li>Analytics: Athena, Redshift</li>
      <li>Orchestration: Step Functions, Airflow, AutoSys</li>
    </ul>
  </section>

  <!-- WORK -->
  <section id="work" class="section alt">
    <h2>Selected Work</h2>

    <div class="card">
      <h3>Databricks â†” Redshift Validation Framework</h3>
      <p>
        Designed and built an automated validation framework to reconcile
        datasets across hundreds of tables between Databricks and Redshift,
        eliminating manual checks and reducing production issues.
      </p>
    </div>

    <div class="card">
      <h3>Scalable Ingestion Framework</h3>
      <p>
        Enhanced ingestion pipelines with retries, monitoring, and alerting,
        improving pipeline reliability and reducing operational overhead.
      </p>
    </div>
  </section>

  <!-- EXPERIENCE -->
  <section class="section">
    <h2>Experience</h2>

    <div class="card">
      <h3>Data Engineer â€” Infosys</h3>
      <p class="meta">Feb 2023 â€“ Present Â· Financial Services Client</p>
      <ul>
        <li>Migrated on-prem systems to AWS using S3, DMS, Glue, and Athena</li>
        <li>Built large-scale PySpark ETL pipelines on Databricks</li>
        <li>Optimized Spark workloads, reducing runtime by 35%</li>
        <li>Orchestrated workflows using Step Functions and Lambda</li>
      </ul>
    </div>

    <div class="card">
      <h3>Data Engineer â€” Infosys</h3>
      <p class="meta">Jan 2022 â€“ Feb 2023 Â· Enterprise Client</p>
      <ul>
        <li>Migrated 20+ databases to AWS using DMS and S3</li>
        <li>Built real-time pipelines using Kinesis and Firehose</li>
        <li>Developed source-to-target validation framework</li>
      </ul>
    </div>
  </section>

  <!-- IMPACT -->
  <section class="section alt">
    <h2>Impact</h2>
    <div class="impact-grid">
      <div>20+ databases migrated</div>
      <div>35% Spark performance gain</div>
      <div>Near real-time pipelines</div>
      <div>Enterprise-scale data platforms</div>
    </div>
  </section>

  <!-- WHAT I DON'T DO -->
  <section class="section">
    <h2>What I Donâ€™t Do</h2>
    <ul class="list">
      <li>Ship pipelines without monitoring</li>
      <li>Hardcode schemas or credentials</li>
      <li>Ignore cost and performance metrics</li>
    </ul>
  </section>

  <!-- CURRENT -->
  <section class="section alt">
    <h2>Currently Exploring</h2>
    <ul class="list">
      <li>Lakehouse optimizations</li>
      <li>Automated data quality frameworks</li>
      <li>GenAI for data operations</li>
    </ul>
  </section>

  <!-- CONTACT -->
  <section class="section">
    <h2>Contact</h2>
    <p>ðŸ“§ <a href="mailto:sanjayambati9@gmail.com">sanjayambati9@gmail.com</a></p>
    <p>ðŸ”— <a href="https://linkedin.com/in/sanjayambati" target="_blank">linkedin.com/in/sanjayambati</a></p>
    <p>ðŸ’» <a href="https://github.com/Sanjay-de" target="_blank">github.com/Sanjay-de</a></p>
  </section>

  <footer>
    <p>
      Good data engineering is invisible â€” until it fails.<br/>
      Â© 2026 Sanjay Ambati
    </p>
  </footer>

</body>
</html>